{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Project 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will procced according to the KDD Process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code first load all the .log files in the..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /Users/vatsal/Desktop/SimplyTag/orgadata-st8.log\n",
      "Processing file: /Users/vatsal/Desktop/SimplyTag/combined_logs.log\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-176edb8d9c7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Read the log file line by line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0;31m# Find the JSON part of each line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mjson_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Folder path containing all .log files\n",
    "folder_path = \"/Users/vatsal/Desktop/SimplyTag\"  # Replace with your folder path\n",
    "output_csv_path = \"/Users/vatsal/Desktop/SimplyTag/merged_logs.csv\"\n",
    "\n",
    "# Initialize a list to store JSON data from all files\n",
    "log_data = []\n",
    "\n",
    "# Process each .log file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".log\"):  # Check if the file is a .log file\n",
    "        log_file_path = os.path.join(folder_path, file_name)\n",
    "        print(f\"Processing file: {log_file_path}\")\n",
    "        \n",
    "        # Read the log file line by line\n",
    "        with open(log_file_path, \"r\") as file:\n",
    "            for line in file:\n",
    "                # Find the JSON part of each line\n",
    "                json_start = line.find('{')\n",
    "                if json_start != -1:\n",
    "                    json_data = line[json_start:].strip()\n",
    "                    try:\n",
    "                        # Parse the JSON and append it to the list\n",
    "                        log_data.append(json.loads(json_data))\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Skipping invalid JSON in file {file_name}: {json_data}\")\n",
    "\n",
    "# Convert the combined list of JSON objects to a DataFrame\n",
    "if log_data:\n",
    "    df = pd.DataFrame(log_data)\n",
    "\n",
    "    # Save the DataFrame to a single CSV file\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"All log data successfully merged and saved to {output_csv_path}\")\n",
    "else:\n",
    "    print(\"No valid log entries found in the provided files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/vatsal/Desktop/SimplyTag/merged_logs.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Level', 'Timestamp', 'PID', 'Logger', 'Message', 'Scope',\n",
      "       'Application', 'State', 'EventId', 'Exception'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of         Level                     Timestamp      PID  \\\n",
       "0        INFO  2024-11-29T23:00:22.7045112Z      668   \n",
       "1        INFO  2024-11-29T23:00:22.7065968Z      668   \n",
       "2        INFO  2024-11-29T23:00:22.7104302Z      668   \n",
       "3        INFO  2024-11-29T23:00:22.7112929Z      668   \n",
       "4        INFO  2024-11-29T23:00:22.7124052Z      668   \n",
       "...       ...                           ...      ...   \n",
       "2144399  INFO  2024-11-19T23:00:03.2857262Z  2151322   \n",
       "2144400  INFO  2024-11-19T23:00:03.2859194Z  2151322   \n",
       "2144401  INFO  2024-11-19T23:00:03.2861440Z  2151322   \n",
       "2144402  INFO  2024-11-19T23:00:03.2863937Z  2151322   \n",
       "2144403  INFO  2024-11-19T23:00:03.2865924Z  2151322   \n",
       "\n",
       "                                                    Logger  \\\n",
       "0                 Microsoft.AspNetCore.Hosting.Diagnostics   \n",
       "1        Microsoft.AspNetCore.HttpLogging.HttpLoggingMi...   \n",
       "2          Microsoft.AspNetCore.Routing.EndpointMiddleware   \n",
       "3        Microsoft.AspNetCore.Mvc.Infrastructure.Contro...   \n",
       "4        Microsoft.AspNetCore.Mvc.Infrastructure.Contro...   \n",
       "...                                                    ...   \n",
       "2144399  Microsoft.AspNetCore.Mvc.Infrastructure.Contro...   \n",
       "2144400    Microsoft.AspNetCore.Routing.EndpointMiddleware   \n",
       "2144401  Microsoft.AspNetCore.HttpLogging.HttpLoggingMi...   \n",
       "2144402  Microsoft.AspNetCore.HttpLogging.HttpLoggingMi...   \n",
       "2144403           Microsoft.AspNetCore.Hosting.Diagnostics   \n",
       "\n",
       "                                                   Message  \\\n",
       "0        Request starting HTTP/1.1 GET http://api.owds....   \n",
       "1        Request:\\nProtocol: HTTP/1.1\\nMethod: GET\\nSch...   \n",
       "2        Executing endpoint 'Ofcas.Datasafe.WebApi.Cont...   \n",
       "3        Route matched with {action = \"GetApiVersionsV2...   \n",
       "4        Executing action method Ofcas.Datasafe.WebApi....   \n",
       "...                                                    ...   \n",
       "2144399  Executed action Ofcas.Datasafe.WebApi.Controll...   \n",
       "2144400  Executed endpoint 'Ofcas.Datasafe.WebApi.Contr...   \n",
       "2144401  ResponseBody: {\"assemblyVersion\":\"1.81.0+4ae2c...   \n",
       "2144402                                 Duration: 4.1801ms   \n",
       "2144403  Request finished HTTP/1.1 GET http://api.owds....   \n",
       "\n",
       "                                                     Scope  \\\n",
       "0        {'ParentId': '0000000000000000', 'ConnectionId...   \n",
       "1        {'ParentId': '0000000000000000', 'ConnectionId...   \n",
       "2        {'ParentId': '0000000000000000', 'ConnectionId...   \n",
       "3        {'ParentId': '0000000000000000', 'ConnectionId...   \n",
       "4        {'ParentId': '0000000000000000', 'ConnectionId...   \n",
       "...                                                    ...   \n",
       "2144399  {'SpanId': 'c5f709aa31ba03d3', 'ParentId': '00...   \n",
       "2144400  {'SpanId': 'c5f709aa31ba03d3', 'ParentId': '00...   \n",
       "2144401  {'SpanId': 'c5f709aa31ba03d3', 'ParentId': '00...   \n",
       "2144402  {'SpanId': 'c5f709aa31ba03d3', 'ParentId': '00...   \n",
       "2144403  {'SpanId': 'c5f709aa31ba03d3', 'ParentId': '00...   \n",
       "\n",
       "                                               Application  \\\n",
       "0        {'Name': 'Ofcas.Datasafe.WebApi', 'Version': '...   \n",
       "1        {'Name': 'Ofcas.Datasafe.WebApi', 'Version': '...   \n",
       "2        {'Name': 'Ofcas.Datasafe.WebApi', 'Version': '...   \n",
       "3        {'Name': 'Ofcas.Datasafe.WebApi', 'Version': '...   \n",
       "4        {'Name': 'Ofcas.Datasafe.WebApi', 'Version': '...   \n",
       "...                                                    ...   \n",
       "2144399  {'Name': 'Ofcas.Datasafe.WebApi', 'Version': '...   \n",
       "2144400  {'Name': 'Ofcas.Datasafe.WebApi', 'Version': '...   \n",
       "2144401  {'Name': 'Ofcas.Datasafe.WebApi', 'Version': '...   \n",
       "2144402  {'Name': 'Ofcas.Datasafe.WebApi', 'Version': '...   \n",
       "2144403  {'Name': 'Ofcas.Datasafe.WebApi', 'Version': '...   \n",
       "\n",
       "                                                     State  \\\n",
       "0        {'Protocol': 'HTTP/1.1', 'Method': 'GET', 'Con...   \n",
       "1        {'Protocol': 'HTTP/1.1', 'Method': 'GET', 'Sch...   \n",
       "2        {'EndpointName': 'Ofcas.Datasafe.WebApi.Contro...   \n",
       "3        {'RouteData': '{action = \"GetApiVersionsV2\", c...   \n",
       "4        {'ActionName': 'Ofcas.Datasafe.WebApi.Controll...   \n",
       "...                                                    ...   \n",
       "2144399  {'ActionName': 'Ofcas.Datasafe.WebApi.Controll...   \n",
       "2144400  {'EndpointName': 'Ofcas.Datasafe.WebApi.Contro...   \n",
       "2144401  {'Body': '{\"assemblyVersion\":\"1.81.0+4ae2cf530...   \n",
       "2144402  {'Duration': 4.1801, '{OriginalFormat}': 'Dura...   \n",
       "2144403  {'ElapsedMilliseconds': 5.0362, 'StatusCode': ...   \n",
       "\n",
       "                                                  EventId Exception  \n",
       "0                                 {'Id': 1, 'Name': None}       NaN  \n",
       "1                         {'Id': 1, 'Name': 'RequestLog'}       NaN  \n",
       "2                  {'Id': 0, 'Name': 'ExecutingEndpoint'}       NaN  \n",
       "3        {'Id': 102, 'Name': 'ControllerActionExecuting'}       NaN  \n",
       "4            {'Id': 101, 'Name': 'ActionMethodExecuting'}       NaN  \n",
       "...                                                   ...       ...  \n",
       "2144399             {'Id': 105, 'Name': 'ActionExecuted'}       NaN  \n",
       "2144400             {'Id': 1, 'Name': 'ExecutedEndpoint'}       NaN  \n",
       "2144401                 {'Id': 4, 'Name': 'ResponseBody'}       NaN  \n",
       "2144402                     {'Id': 8, 'Name': 'Duration'}       NaN  \n",
       "2144403                           {'Id': 2, 'Name': None}       NaN  \n",
       "\n",
       "[2144404 rows x 10 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data Selection:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Entry from 'State':\n",
      " {'Protocol': 'HTTP/1.1', 'Method': 'GET', 'ContentType': None, 'ContentLength': None, 'Scheme': 'http', 'Host': 'api.owds.org', 'PathBase': '', 'Path': '/api/v2/versions', 'QueryString': '', '{OriginalFormat}': 'Request starting {Protocol} {Method} {Scheme}://{Host}{PathBase}{Path}{QueryString} - {ContentType} {ContentLength}'}\n",
      "Extracted Data:\n",
      "                       Timestamp                          Trace-id  \\\n",
      "0  2024-11-29T23:00:22.7045112Z  3dff50eaf246e6cc55173db4092d5187   \n",
      "1  2024-11-29T23:00:22.7065968Z  3dff50eaf246e6cc55173db4092d5187   \n",
      "2  2024-11-29T23:00:22.7104302Z  3dff50eaf246e6cc55173db4092d5187   \n",
      "3  2024-11-29T23:00:22.7112929Z  3dff50eaf246e6cc55173db4092d5187   \n",
      "4  2024-11-29T23:00:22.7124052Z  3dff50eaf246e6cc55173db4092d5187   \n",
      "\n",
      "   HTTP Status Code              Path  \\\n",
      "0               NaN              None   \n",
      "1               NaN  /api/v2/versions   \n",
      "2               NaN              None   \n",
      "3               NaN              None   \n",
      "4               NaN              None   \n",
      "\n",
      "                                     User Agent  \n",
      "0                                          None  \n",
      "1  check_http/v2.4.0 (monitoring-plugins 2.4.0)  \n",
      "2                                          None  \n",
      "3                                          None  \n",
      "4                                          None  \n",
      "Selected data has been saved to /Users/vatsal/Desktop/SimplyTag/selected_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"/Users/vatsal/Desktop/SimplyTag/merged_logs.csv\", low_memory=False)\n",
    "\n",
    "# Check a sample entry to understand the structure\n",
    "print(\"Sample Entry from 'State':\\n\", df['State'].iloc[0])\n",
    "\n",
    "# Function to safely parse JSON\n",
    "def parse_json_safe(json_str):\n",
    "    try:\n",
    "        # Replace single quotes with double quotes for valid JSON\n",
    "        return json.loads(json_str.replace(\"'\", '\"'))\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return None\n",
    "\n",
    "# Parse 'Scope' and 'State' columns\n",
    "df['Scope'] = df['Scope'].apply(lambda x: parse_json_safe(x) if isinstance(x, str) else None)\n",
    "df['State'] = df['State'].apply(lambda x: parse_json_safe(x) if isinstance(x, str) else None)\n",
    "\n",
    "# Initialize a new DataFrame for selected data\n",
    "df_selected0 = pd.DataFrame()\n",
    "\n",
    "# Extract specific fields after parsing JSON\n",
    "df_selected0['Timestamp'] = df['Timestamp']\n",
    "df_selected0['Trace-id'] = df['Scope'].apply(lambda x: x.get('TraceId') if isinstance(x, dict) else None)\n",
    "df_selected0['HTTP Status Code'] = df['State'].apply(lambda x: x.get('StatusCode') if isinstance(x, dict) else None)\n",
    "df_selected0['Path'] = df['State'].apply(lambda x: x.get('Path') if isinstance(x, dict) else None)\n",
    "df_selected0['User Agent'] = df['State'].apply(lambda x: x.get('User-Agent') if isinstance(x, dict) else None)\n",
    "\n",
    "# Inspect the extracted data\n",
    "print(\"Extracted Data:\\n\", df_selected0.head())\n",
    "\n",
    "# Save the cleaned and selected data to a new CSV file\n",
    "output_csv_path = \"/Users/vatsal/Desktop/SimplyTag/selected_data.csv\"\n",
    "df_selected0.to_csv(output_csv_path, index=False)\n",
    "print(f\"Selected data has been saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we need to procced with the new selected data. So we are loading the selected_data file which we have created and then print the new data-frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = pd.read_csv(\"/Users/vatsal/Desktop/SimplyTag/selected_data.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User Agent    188\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selected\n",
    "df_selected[['User Agent']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with non-null 'User Agent': 179148\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows with non-null 'User Agent':\", df_selected['User Agent'].notnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with non-null 'Trace-id': 2045561\n",
      "Rows with non-null 'HTTP Status Code': 312027\n",
      "Rows with non-null 'Path': 296979\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows with non-null 'Trace-id':\", df_selected['Trace-id'].notnull().sum())\n",
    "print(\"Rows with non-null 'HTTP Status Code':\", df_selected['HTTP Status Code'].notnull().sum())\n",
    "print(\"Rows with non-null 'Path':\", df_selected['Path'].notnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows meeting all conditions: 0\n"
     ]
    }
   ],
   "source": [
    "valid_rows = df_selected[\n",
    "    df_selected['User Agent'].notnull() &\n",
    "    df_selected['Trace-id'].notnull() &\n",
    "    df_selected['HTTP Status Code'].notnull() &\n",
    "    df_selected['Path'].notnull()\n",
    "]\n",
    "print(\"Rows meeting all conditions:\", len(valid_rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows reserved with non-null 'User Agent': 179148\n",
      "Rows after dropping rows with missing values in critical fields: 0\n",
      "Cleaned data preview:\n",
      " Empty DataFrame\n",
      "Columns: [Timestamp, Trace-id, HTTP Status Code, Path, User Agent]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Trace-id</th>\n",
       "      <th>HTTP Status Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>User Agent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Timestamp, Trace-id, HTTP Status Code, Path, User Agent]\n",
       "Index: []"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Reserve rows where 'User Agent' is not null\n",
    "df_with_user_agent = df_selected[df_selected['User Agent'].notnull()]\n",
    "print(f\"Rows reserved with non-null 'User Agent': {len(df_with_user_agent)}\")\n",
    "\n",
    "# Step 2: Drop rows with missing values in critical fields from the reserved rows\n",
    "df_cleaned = df_with_user_agent.dropna(subset=['Trace-id', 'HTTP Status Code', 'Path'])\n",
    "print(f\"Rows after dropping rows with missing values in critical fields: {len(df_cleaned)}\")\n",
    "\n",
    "# Inspect the cleaned data\n",
    "print(\"Cleaned data preview:\\n\", df_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Summary:\n",
      " Timestamp                 0\n",
      "Trace-id              98843\n",
      "HTTP Status Code    1832377\n",
      "Path                1847425\n",
      "User Agent          1965256\n",
      "dtype: int64\n",
      "Data after handling missing values while retaining rows with 'User Agent':\n",
      " Empty DataFrame\n",
      "Columns: [Timestamp, Trace-id, HTTP Status Code, Path, User Agent]\n",
      "Index: []\n",
      "Number of unique User Agents: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_summary = df_selected.isnull().sum()\n",
    "print(\"Missing Values Summary:\\n\", missing_summary)\n",
    "\n",
    "# Retain rows where 'User Agent' is not null\n",
    "df_with_user_agent = df_selected[df_selected['User Agent'].notnull()]\n",
    "df_with_user_agent['User Agent'].nunique()\n",
    "# Drop rows with missing values in critical fields but retain rows with valid 'User Agent'\n",
    "df_final = df_with_user_agent.dropna(subset=['Trace-id', 'HTTP Status Code', 'Path']).copy()\n",
    "\n",
    "print(\"Data after handling missing values while retaining rows with 'User Agent':\\n\", df_final.head())\n",
    "print(\"Number of unique User Agents:\", df_final['User Agent'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after removing duplicates: 106480 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Trace-id</th>\n",
       "      <th>HTTP Status Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>User Agent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024-11-29T23:00:22.7170405Z</td>\n",
       "      <td>3dff50eaf246e6cc55173db4092d5187</td>\n",
       "      <td>200.0</td>\n",
       "      <td>/api/v2/versions</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2024-11-29T23:00:36.5883159Z</td>\n",
       "      <td>bb52744079ab054a8189bf62d8602370</td>\n",
       "      <td>200.0</td>\n",
       "      <td>/api/v2/versions</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2024-11-29T23:01:12.6574762Z</td>\n",
       "      <td>02316aed810d686f6c7a5fbe693f10ca</td>\n",
       "      <td>200.0</td>\n",
       "      <td>/api/v2/versions</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2024-11-29T23:01:22.8895503Z</td>\n",
       "      <td>005331c774905da73d2d938d1a1fb153</td>\n",
       "      <td>200.0</td>\n",
       "      <td>/api/v2/versions</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2024-11-29T23:01:36.7376115Z</td>\n",
       "      <td>83019acd478b0e66cf0e90a932f663de</td>\n",
       "      <td>200.0</td>\n",
       "      <td>/api/v2/versions</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144327</th>\n",
       "      <td>2024-11-19T22:58:58.9054399Z</td>\n",
       "      <td>8f56736ae00d6d0905149e664675d3e3</td>\n",
       "      <td>200.0</td>\n",
       "      <td>/api/v2/versions</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144340</th>\n",
       "      <td>2024-11-19T22:59:03.0837242Z</td>\n",
       "      <td>938fb7915bf6d0bbf1f0cd0f0155acf1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>/api/v2/versions</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144369</th>\n",
       "      <td>2024-11-19T22:59:55.7616546Z</td>\n",
       "      <td>0cfdcd4505ca4f1969017713cc115bff</td>\n",
       "      <td>200.0</td>\n",
       "      <td>/api/v2/versions</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144390</th>\n",
       "      <td>2024-11-19T22:59:59.0769271Z</td>\n",
       "      <td>c04e0c475d8a6a9e673f00ae3bb74e41</td>\n",
       "      <td>200.0</td>\n",
       "      <td>/api/v2/versions</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144403</th>\n",
       "      <td>2024-11-19T23:00:03.2865924Z</td>\n",
       "      <td>e633e492116f3febe619bfed47449e89</td>\n",
       "      <td>200.0</td>\n",
       "      <td>/api/v2/versions</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106480 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Timestamp                          Trace-id  \\\n",
       "12       2024-11-29T23:00:22.7170405Z  3dff50eaf246e6cc55173db4092d5187   \n",
       "28       2024-11-29T23:00:36.5883159Z  bb52744079ab054a8189bf62d8602370   \n",
       "62       2024-11-29T23:01:12.6574762Z  02316aed810d686f6c7a5fbe693f10ca   \n",
       "75       2024-11-29T23:01:22.8895503Z  005331c774905da73d2d938d1a1fb153   \n",
       "88       2024-11-29T23:01:36.7376115Z  83019acd478b0e66cf0e90a932f663de   \n",
       "...                               ...                               ...   \n",
       "2144327  2024-11-19T22:58:58.9054399Z  8f56736ae00d6d0905149e664675d3e3   \n",
       "2144340  2024-11-19T22:59:03.0837242Z  938fb7915bf6d0bbf1f0cd0f0155acf1   \n",
       "2144369  2024-11-19T22:59:55.7616546Z  0cfdcd4505ca4f1969017713cc115bff   \n",
       "2144390  2024-11-19T22:59:59.0769271Z  c04e0c475d8a6a9e673f00ae3bb74e41   \n",
       "2144403  2024-11-19T23:00:03.2865924Z  e633e492116f3febe619bfed47449e89   \n",
       "\n",
       "         HTTP Status Code              Path User Agent  \n",
       "12                  200.0  /api/v2/versions        NaN  \n",
       "28                  200.0  /api/v2/versions        NaN  \n",
       "62                  200.0  /api/v2/versions        NaN  \n",
       "75                  200.0  /api/v2/versions        NaN  \n",
       "88                  200.0  /api/v2/versions        NaN  \n",
       "...                   ...               ...        ...  \n",
       "2144327             200.0  /api/v2/versions        NaN  \n",
       "2144340             200.0  /api/v2/versions        NaN  \n",
       "2144369             200.0  /api/v2/versions        NaN  \n",
       "2144390             200.0  /api/v2/versions        NaN  \n",
       "2144403             200.0  /api/v2/versions        NaN  \n",
       "\n",
       "[106480 rows x 5 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicate entries based on critical columns\n",
    "df_dropduplicate = df_dropped.drop_duplicates(subset=['Timestamp', 'Trace-id', 'HTTP Status Code', 'Path'])\n",
    "\n",
    "print(f\"Data after removing duplicates: {len(df_dropduplicate)} rows\")\n",
    "df_dropduplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Timestamp        Date  Hour Day_of_week\n",
      "12 2024-11-29 23:00:22.717040500+00:00  2024-11-29    23      Friday\n",
      "28 2024-11-29 23:00:36.588315900+00:00  2024-11-29    23      Friday\n",
      "62 2024-11-29 23:01:12.657476200+00:00  2024-11-29    23      Friday\n",
      "75 2024-11-29 23:01:22.889550300+00:00  2024-11-29    23      Friday\n",
      "88 2024-11-29 23:01:36.737611500+00:00  2024-11-29    23      Friday\n"
     ]
    }
   ],
   "source": [
    "# Convert timestamp to datetime format\n",
    "df_dropduplicate['Timestamp'] = pd.to_datetime(df_dropduplicate['Timestamp'], errors='coerce')\n",
    "\n",
    "# Remove rows with invalid timestamps\n",
    "df_dropduplicate = df_dropduplicate.dropna(subset=['Timestamp'])\n",
    "\n",
    "# Optionally, create new time-related columns\n",
    "df_dropduplicate['Date'] = df_dropduplicate['Timestamp'].dt.date\n",
    "df_dropduplicate['Hour'] = df_dropduplicate['Timestamp'].dt.hour\n",
    "df_dropduplicate['Day_of_week'] = df_dropduplicate['Timestamp'].dt.day_name()\n",
    "\n",
    "print(df_dropduplicate[['Timestamp', 'Date', 'Hour', 'Day_of_week']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample User Agent Normalization:\n",
      "    User Agent User_Agent_Normalized\n",
      "12        NaN                   NaN\n",
      "28        NaN                   NaN\n",
      "62        NaN                   NaN\n",
      "75        NaN                   NaN\n",
      "88        NaN                   NaN\n"
     ]
    }
   ],
   "source": [
    "# Normalize user agent strings (basic example)\n",
    "df_dropduplicate['User_Agent_Normalized'] = df_dropduplicate['User Agent'].str.lower().str.strip()\n",
    "\n",
    "print(\"Sample User Agent Normalization:\\n\", df_dropduplicate[['User Agent', 'User_Agent_Normalized']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after filtering valid status codes: 102767 rows\n"
     ]
    }
   ],
   "source": [
    "# Define valid HTTP status codes\n",
    "valid_status_codes = [200, 404]\n",
    "\n",
    "# Filter rows with valid status codes\n",
    "df_dropduplicate = df_dropduplicate[df_dropduplicate['HTTP Status Code'].isin(valid_status_codes)]\n",
    "\n",
    "print(f\"Data after filtering valid status codes: {len(df_dropduplicate)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   User Agent user_agent_category\n",
      "12        NaN             Unknown\n",
      "28        NaN             Unknown\n",
      "62        NaN             Unknown\n",
      "75        NaN             Unknown\n",
      "88        NaN             Unknown\n"
     ]
    }
   ],
   "source": [
    "def categorize_user_agent(user_agent):\n",
    "    if pd.isnull(user_agent) or user_agent.strip() == \"\":\n",
    "        return \"Unknown\"\n",
    "    elif \"bot\" in user_agent.lower() or \"spider\" in user_agent.lower():\n",
    "        return \"Bot\"\n",
    "    elif \"curl\" in user_agent.lower() or \"wget\" in user_agent.lower():\n",
    "        return \"Script\"\n",
    "    elif \"mozilla\" in user_agent.lower():\n",
    "        return \"Browser\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "# Apply the categorization using .loc\n",
    "df_dropduplicate.loc[:, 'user_agent_category'] = df_dropduplicate['User Agent'].apply(categorize_user_agent)\n",
    "\n",
    "print(df_dropduplicate[['User Agent', 'user_agent_category']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User Agent    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dropduplicate[['User Agent']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
